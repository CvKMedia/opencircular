# OpenCircular

[![CI](https://github.com/opencircular/opencircular/workflows/CI/badge.svg)](https://github.com/opencircular/opencircular/actions)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

A production-ready AI provider connectivity platform that enables seamless integration with multiple AI services including Google Gemini and OpenAI-compatible endpoints.

## ğŸš€ Features

- **Multi-Provider Support**: Connect to Gemini, OpenAI, OpenRouter, Together, and custom OpenAI-compatible endpoints
- **Real-time Health Monitoring**: Active connectivity checks and latency monitoring for all providers
- **Interactive Playground**: Test AI providers with a clean, responsive chat interface
- **Production Ready**: Built with FastAPI + Next.js, containerized with Docker, deployed on Render
- **Type Safe**: Full TypeScript support on frontend, Python type hints on backend
- **CI/CD Pipeline**: Automated testing and deployment with GitHub Actions

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚  AI Providers   â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚                 â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚ â€¢ Gemini        â”‚
â”‚ â€¢ Landing Page  â”‚    â”‚ â€¢ /api/ai/chat  â”‚    â”‚ â€¢ OpenAI        â”‚
â”‚ â€¢ Playground    â”‚    â”‚ â€¢ /health       â”‚    â”‚ â€¢ OpenRouter    â”‚
â”‚ â€¢ Health Status â”‚    â”‚ â€¢ /health/ai    â”‚    â”‚ â€¢ Together      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ Custom        â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš¦ Quick Start

### Prerequisites

- Docker and Docker Compose
- Node.js 20+ (for local development)
- Python 3.11+ (for local development)
- AI Provider API Keys (see [Environment Variables](#environment-variables))

### Local Development

1. **Clone the repository**
   ```bash
   git clone https://github.com/opencircular/opencircular.git
   cd opencircular
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Start the backend**
   ```bash
   cd backend
   pip install -e .[dev]
   uvicorn opencircular_backend.app:app --host 0.0.0.0 --port 8000 --reload
   ```

4. **Start the frontend** (in a new terminal)
   ```bash
   cd frontend
   npm install
   npm run dev
   ```

5. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

### Docker Development

```bash
# Build and run with Docker Compose
docker-compose up --build

# Access the application
# Frontend: http://localhost:3000
# Backend: http://localhost:8000
```

## ğŸŒ Deployment

### Deploy to Render

1. **Fork this repository**

2. **Connect to Render**
   - Go to [Render Dashboard](https://dashboard.render.com)
   - Click "New" â†’ "Blueprint"
   - Connect your GitHub repository
   - Select the `render.yaml` file

3. **Configure Environment Variables**
   Set the following in your Render service settings:
   
   **Backend Service:**
   ```
   GEMINI_API_KEY=your_gemini_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   AI_PROVIDER=gemini  # or openai, openrouter, together
   ```

4. **Deploy**
   - Render will automatically build and deploy both services
   - Your app will be available at the provided URLs

### Manual Deployment

For other platforms, use the provided Docker images:

```bash
# Build images
docker build -t opencircular-backend ./backend
docker build -t opencircular-frontend ./frontend

# Run containers
docker run -p 8000:8000 --env-file .env opencircular-backend
docker run -p 3000:3000 -e NEXT_PUBLIC_API_BASE=http://your-backend-url opencircular-frontend
```

## âš™ï¸ Environment Variables

### Backend Configuration

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `PORT` | Backend server port | `8000` | No |
| `CORS_ALLOWED_ORIGINS` | Comma-separated list of allowed origins | `http://localhost:3000` | No |
| `AI_PROVIDER` | Default AI provider | `gemini` | No |

### Gemini Configuration

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `GEMINI_API_KEY` | Google Gemini API key | - | Yes (if using Gemini) |
| `GEMINI_MODEL` | Gemini model name | `gemini-1.5-flash` | No |

### OpenAI-Compatible Configuration

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `OPENAI_API_KEY` | API key for OpenAI-compatible service | - | Yes (if using OpenAI-compatible) |
| `OPENAI_BASE_URL` | Base URL for OpenAI-compatible API | `https://api.openai.com/v1` | No |
| `OPENAI_MODEL` | Model name | `gpt-4o-mini` | No |

### Frontend Configuration

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `NEXT_PUBLIC_API_BASE` | Backend API base URL | `http://localhost:8000` | No |

### Provider-Specific URLs

For different providers, set `OPENAI_BASE_URL` to:

- **OpenAI**: `https://api.openai.com/v1` (default)
- **OpenRouter**: `https://openrouter.ai/api/v1`
- **Together**: `https://api.together.xyz/v1`
- **Local vLLM**: `http://localhost:8000/v1`
- **Local Ollama**: `http://localhost:11434/v1`

## ğŸ”§ API Reference

### Chat Endpoint

**POST** `/api/ai/chat`

```json
{
  "messages": [
    {"role": "user", "content": "Hello, how are you?"}
  ]
}
```

**Response:**
```json
{
  "reply": "Hello! I'm doing well, thank you for asking. How can I help you today?"
}
```

### Health Endpoints

**GET** `/health` - Basic health check

```json
{"status": "ok"}
```

**GET** `/health/ai` - AI providers health check

```json
{
  "providers": [
    {
      "provider": "gemini",
      "ok": true,
      "latency_ms": 245.67,
      "response": "7"
    },
    {
      "provider": "openai-compat",
      "ok": false,
      "error": "Not configured (missing OPENAI_API_KEY)"
    }
  ]
}
```

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend
pip install -e .[dev]
pytest tests/ -v
```

### Frontend Type Checking

```bash
cd frontend
npm install
npm run type-check
```

### Integration Testing

```bash
# Start services
docker-compose up -d

# Test health endpoints
curl http://localhost:8000/health
curl http://localhost:8000/health/ai

# Test chat endpoint
curl -X POST http://localhost:8000/api/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "Say exactly: OpenCircular OK"}]}'
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ SECURITY.md
â”œâ”€â”€ GOVERNANCE.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .env.example
â”œâ”€â”€ render.yaml                    # Render deployment config
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                 # GitHub Actions CI
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ pyproject.toml             # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ uvicorn_start.sh
â”‚   â”œâ”€â”€ src/opencircular_backend/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                 # FastAPI application
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py            # Provider protocol
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini.py          # Gemini implementation
â”‚   â”‚   â”‚   â””â”€â”€ openai_compat.py   # OpenAI-compatible implementation
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ ai.py              # Chat endpoints
â”‚   â”‚       â””â”€â”€ health.py          # Health endpoints
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_health.py
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ next.config.js
    â”œâ”€â”€ tsconfig.json
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ .dockerignore
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ layout.tsx
    â”‚   â”œâ”€â”€ page.tsx               # Landing page
    â”‚   â”œâ”€â”€ globals.css
    â”‚   â”œâ”€â”€ playground/
    â”‚   â”‚   â””â”€â”€ page.tsx           # Chat playground
    â”‚   â””â”€â”€ health/
    â”‚       â””â”€â”€ page.tsx           # Health dashboard
    â””â”€â”€ lib/
        â””â”€â”€ api.ts                 # API client functions
```

## ğŸ”’ Security

- API keys are never committed to the repository
- CORS is configured to allow only specified origins
- Input validation on all endpoints
- Request size limits (4KB for chat requests)
- Health checks use minimal test prompts
- Timeouts on all external API calls

For security issues, please see [SECURITY.md](SECURITY.md).

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Workflow

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `npm test` (frontend) and `pytest` (backend)
5. Commit using conventional commits: `git commit -m 'feat: add amazing feature'`
6. Push to your branch: `git push origin feature/amazing-feature`
7. Open a Pull Request

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) for the excellent Python web framework
- [Next.js](https://nextjs.org/) for the React framework
- [Render](https://render.com/) for simple cloud deployment
- [Google Gemini](https://ai.google.dev/) and [OpenAI](https://openai.com/) for AI capabilities

## ğŸ“ Support

- ğŸ“– [Documentation](https://github.com/opencircular/opencircular/wiki)
- ğŸ› [Issue Tracker](https://github.com/opencircular/opencircular/issues)
- ğŸ’¬ [Discussions](https://github.com/opencircular/opencircular/discussions)
- ğŸ“§ [Email](mailto:support@opencircular.org)

---

**Built with â¤ï¸ by the OpenCircular team**
